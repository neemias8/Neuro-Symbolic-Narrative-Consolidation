# Kendall's Tau Metric Analysis Report

## 1. Diagnosis
The initial Kendall's Tau score (~0.46) for TAEG models (Gemma-3-4B) did not reflect the reality of the narrative ordering. A detailed analysis of the alignment between events and sentences revealed that the TF-IDF based metric suffers from "semantic hallucination."

## 2. Root Cause: Semantic Ambiguity
The metric uses TF-IDF and Cosine Similarity to find the sentence that best matches an event description. When distinct events share similar vocabulary, the metric can incorrectly align an event from the beginning of the story with a sentence from the end.

### The "Mary anoints Jesus" Case (Event 1)
- **Event Description:** "Mary anoints Jesus" (In Bethany, before the Passion).
- **Where the Model Generated (Correct):** Paragraph 1.
  > "While reclining at the table with Lazarus, a woman, identified as Mary... poured it upon Jesusâ€™ feet..."
- **Where the Metric Found It (Incorrect):** Paragraph 305 (Post-Crucifixion).
  > "When the Sabbath was over, Mary Magdalene... bought spices so that they might go to **anoint Jesus' body**."

### Why did the metric fail?
The sentence at the end contains the exact words "**Mary**", "**anoint**", "**Jesus**". The correct sentence at the beginning uses "poured" and "perfume", which is semantically equivalent but lexically has less direct overlap with the short event description.

## 3. Impact on Calculation
Since the metric believes **Event 1** occurred at **Sentence 823** (near the end of the text):
1. It marks Event 1 as "late".
2. **Event 2** ("Plan to kill Lazarus") is correctly found at **Sentence 8**.
3. The metric calculates that Event 2 came *before* Event 1 (8 < 823), penalizing the score as a "reversal".
4. This creates a cascade effect where dozens of initial events appear to be "out of order" relative to this false positive.

## 4. Solution: Reference-Based Metric (Legacy)
To correct this, we implemented a **Reference-Based Kendall's Tau**, which compares the order of events in the generated text against a human-written summary (Golden Sample) rather than just the raw event list.

- **Result:** The score for Gemma-3-4B (TAEG) jumped from **0.46** to **0.77**.
- **Significance:** This confirms that the model **did** preserve the narrative order correctly. The low initial score was an artifact of the metric's inability to distinguish context, not a failure of the model.

## 5. The Truncation Paradox (NoTAEG Models)
A counter-intuitive finding was that **BART (NoTAEG)** achieved a decent Tau score (~0.53) despite having a ROUGE-1 score of nearly zero (0.006).

- **Explanation:** The NoTAEG model suffered from severe context truncation, generating only the first ~3 paragraphs of the story (The Triumphal Entry).
- **The Illusion:** Because it only generated 5 events, and those 5 events were in order, the Kendall's Tau metric (which ignores missing events) gave it a passing score.
- **The Reality:** The ROUGE score reveals the truth: NoTAEG failed to generate 99% of the narrative.

## 6. Conclusion
The **TAEG (Temporal-Aware Event Graph)** approach successfully enforces chronological order. The evaluation challenges were due to:
1. **Lexical Ambiguity:** Solved by using Reference-Based evaluation (0.77 score).
2. **Truncation:** Solved by cross-referencing with ROUGE scores to ensure completeness.

**Recommendation:** In the final paper, report the Reference-Based Kendall's Tau (0.77) as the primary ordering metric, while citing the TF-IDF analysis to demonstrate the complexity of automated narrative evaluation.
