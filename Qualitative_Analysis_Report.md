# Qualitative Analysis Report: Neuro-Symbolic Narrative Consolidation
**Date:** November 21, 2025
**Subject:** Manual Inspection of Generated Narratives vs. Golden Sample

## 1. Executive Summary
A qualitative inspection was performed on the output files generated by the pipeline. The goal was to compare the "Consolidated Narrative" against the "Golden Sample" (Biblical ground truth) to identify hallucinations, coherence issues, and the impact of the TAEG (Temporal-Aware Event Graph) methodology.

**Key Findings:**
*   **TAEG Impact:** The Event Graph is critical for smaller LLMs (like Gemma-3-4B). Without it, the model fails to maintain narrative granularity, collapsing the entire story into a single summary paragraph.
*   **Model Suitability:** 
    *   **Gemma-3-4B (with TAEG)** produced the most fluent and accurate narrative.
    *   **PEGASUS** is **unsuitable** for this domain due to severe "news-style" hallucinations (injecting references to modern politics and media).
    *   **BART & PRIMERA** are stable and faithful but stylistically rigid/extractive.

---

## 2. Detailed Model Analysis

### A. Gemma-3-4B (The Impact of TAEG)

#### With TAEG (`Consolidated_Narrative_Gemma-3-4B.txt`)
*   **Status:** ✅ Excellent
*   **Observation:** The model successfully generated a long-form, coherent narrative. It respected the chronological order of events and maintained the integrity of dialogues and parables.
*   **Example (Coherent Output):**
    > "Six days before the Passover, Jesus arrived at Bethany... Meanwhile a large crowd of Jews found out that Jesus was there... As Jesus entered Jerusalem, a wave of excitement and questioning swept through the city..."

#### Without TAEG (`Consolidated_Narrative_Gemma-3-4B_NoTAEG.txt`)
*   **Status:** ❌ Failed (Over-summarization)
*   **Observation:** Without the event-by-event guidance, the model collapsed the entire multi-chapter narrative into a single, high-level summary paragraph. It lost ~90% of the specific details (parables, specific dialogues).
*   **Example (Collapsed Output):**
    > "Okay, here's a consolidated narrative paragraph... As Jesus approached Bethphage... he dispatched two disciples... The crowd... shouted 'Hosanna!'... The following day... he retreated to Bethany... As he died, Jesus’s words fulfilled scripture..."
    *(Note: The entire Passion week was compressed into ~15 lines).*

---

### B. PEGASUS (Severe Hallucinations)

*   **Status:** ⚠️ Critical Failure
*   **Observation:** PEGASUS, being pre-trained heavily on news summarization (CNN/DailyMail, XSum), exhibited severe domain leakage. It treated the Biblical source text as if it were a news feed, injecting "fake news" headers, references to modern newspapers (NYT, WSJ), and completely unrelated modern political events.

#### Examples of Hallucinations found in `Consolidated_Narrative_PEGASUS.txt`:

1.  **Modern Media Injection:**
    > "– The **New York Times** is out with a correction to an old story about Jesus, and it's a doozy."
    > "– The **Vatican** today issued a warning to members of the Catholic Church..."

2.  **Political Hallucinations (Trump/China Trade War):**
    > "– **President Trump's tariff war with China** isn't just bad for the US: It's bad for China, too, according to a Wall Street Journal analysis..."
    *(This appears in the middle of the narrative about the End Times/Apocalypse).*

3.  **Irrelevant Context:**
    > "– It's not every day that a Christian website goes on the offensive against **Mormons**, but that's exactly what's happening in Utah."
    > "– In the wake of the **Orlando shooting**, the nation is taking a fresh look at gun control..."

**Conclusion for PEGASUS:** The model cannot distinguish between the source text (Bible) and its pre-training data (News). It is unfit for narrative consolidation of historical/literary texts without significant fine-tuning.

---

### C. BART & PRIMERA (Baseline Stability)

*   **Status:** ✅ Passable / Good
*   **Observation:** Both models produced stable outputs. They followed the narrative closely without hallucinating modern events.
*   **Style:** They tend to be more "extractive," often pasting large chunks of the original text rather than synthesizing new fluent prose like Gemma.
*   **Example (BART):**
    > "Jesus entered the temple area and drove out all who were buying and selling there... 'It is written,' he said to them..."
    *(Accurate, but reads slightly disjointed compared to Gemma's smooth transitions).*

---

## 3. Quantitative vs. Qualitative Correlation

A detailed audit of the metrics (ROUGE, METEOR, BERTScore, Kendall's Tau) was performed to reconcile them with the qualitative findings.

### A. The "Collapse" of NoTAEG (Low ROUGE)
The quantitative metrics accurately reflect the narrative collapse observed in `Gemma-3-4B_NoTAEG`.
*   **Golden Sample Length:** ~16,415 words.
*   **Gemma NoTAEG Length:** ~313 words (1.9% of original).
*   **Metric Result:** ROUGE-1 ~0.03 (3%).
*   **Interpretation:** While the generated text is coherent (Precision ~60%), it fails to cover 96% of the narrative content (Recall ~3.9%). This confirms that without the TAEG structure, the model cannot sustain long-form generation and defaults to extreme summarization.

### B. The "PEGASUS Paradox" (High ROUGE with Hallucinations)
PEGASUS achieved a relatively high ROUGE score (~0.76) despite generating significant hallucinations.
*   **Metric Result:** ROUGE-1 ~0.76.
*   **Interpretation:** ROUGE measures n-gram overlap. PEGASUS copied large chunks of the source text verbatim (high overlap) but interspersed them with "fake news" hallucinations. The metric penalizes the hallucinations slightly (Precision drop) but rewards the massive copying (Recall gain).
*   **Conclusion:** High ROUGE scores do not guarantee semantic validity or absence of hallucinations. Qualitative inspection is essential.

### C. Kendall's Tau Correction
Initial reports showed a Kendall's Tau of 1.0 for all TAEG models, which was an artifact of the pipeline assuming perfect order. After correction using TF-IDF semantic matching:
*   **Gemma (TAEG):** Tau ~0.46 (Strong positive correlation, correct ordering).
*   **Gemma (NoTAEG):** Tau ~0.10 (Near random/collapsed ordering).
*   **Matches:** TAEG models matched ~164/169 events, while NoTAEG matched only ~51/169.

---

## 4. Recommendation

For the final thesis/paper results:
1.  **Highlight Gemma-3-4B + TAEG** as the state-of-the-art configuration for this pipeline.
2.  **Use PEGASUS as a negative case study** on domain mismatch (News Summarization models applied to Narrative Consolidation).
3.  **Use the NoTAEG comparison** to quantitatively and qualitatively prove the value of the Neuro-Symbolic Event Graph approach.
4.  **Emphasize the limitation of ROUGE** in detecting "embedded hallucinations" like those in PEGASUS.
